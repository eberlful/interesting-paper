Transformers Can Represent n-gram Language Models
https://arxiv.org/abs/2404.14994

Understanding Transformers via N-gram Statistics
https://arxiv.org/abs/2407.12034

N-Gram Induction Heads for In-Context RL: Improving Stability and Reducing Data Needs
https://arxiv.org/abs/2411.01958

Research on Constructing a Sentiment Lexicon for the F&B Sector based on the N-gram Framework
https://koreascience.kr/article/JAKO202431953009394.page

Infini-gram: Scaling Unbounded n-gram Language Models to a Trillion Tokens
https://arxiv.org/abs/2401.17377

The Role of n-gram Smoothing in the Age of Neural Networks
https://arxiv.org/abs/2403.17240

N-gram Prediction and Word Difference Representations for Language Modeling
https://arxiv.org/abs/2409.03295

Can Transformers Learn n-gram Language Models?
https://arxiv.org/abs/2410.03001
